Chapter 1
A Perspective on Testing
Why do we test? The two main reasons are to make a judgment about quality or acceptability and
to discover problems. We test because we know that we are fallible—this is especially true in the
domain of software and software-controlled systems. The goal of this chapter is to create a framework within which we can examine software testing.
1.1 Basic Definitions
Much of testing literature is mired in confusing (and sometimes inconsistent) terminology, probably because testing technology has evolved over decades and via scores of writers. The International
Software Testing Qualification Board (ISTQB) has an extensive glossary of testing terms (see the
website http://www.istqb.org/downloads/glossary.html). The terminology here (and throughout
this book) is compatible with the ISTQB definitions, and they, in turn, are compatible with the
standards developed by the Institute of Electronics and Electrical Engineers (IEEE) Computer
Society (IEEE, 1983). To get started, here is a useful progression of terms.
Error—People make errors. A good synonym is mistake. When people make mistakes while
coding, we call these mistakes bugs. Errors tend to propagate; a requirements error may be magnified during design and amplified still more during coding.
Fault—A fault is the result of an error. It is more precise to say that a fault is the representation of an error, where representation is the mode of expression, such as narrative text, Unified
Modeling Language diagrams, hierarchy charts, and source code. Defect (see the ISTQB Glossary)
is a good synonym for fault, as is bug. Faults can be elusive. An error of omission results in a fault
in which something is missing that should be present in the representation. This suggests a useful
refinement; we might speak of faults of commission and faults of omission. A fault of commission
occurs when we enter something into a representation that is incorrect. Faults of omission occur
when we fail to enter correct information. Of these two types, faults of omission are more difficult
to detect and resolve.
Failure—A failure occurs when the code corresponding to a fault executes. Two subtleties
arise here: one is that failures only occur in an executable representation, which is usually taken
to be source code, or more precisely, loaded object code; the second subtlety is that this definition 

Software Testing
© 2010 Taylor & Francis Group, LLC
relates failures only to faults of commission. How can we deal with failures that correspond to
faults of omission? We can push this still further: what about faults that never happen to execute,
or perhaps do not execute for a long time? Reviews (see Chapter 22) prevent many failures by finding faults; in fact, well-done reviews can find faults of omission.
Incident—When a failure occurs, it may or may not be readily apparent to the user (or customer or tester). An incident is the symptom associated with a failure that alerts the user to the
occurrence of a failure.
Test—Testing is obviously concerned with errors, faults, failures, and incidents. A test is the
act of exercising software with test cases. A test has two distinct goals: to find failures or to demonstrate correct execution.
Test case—A test case has an identity and is associated with a program behavior. It also has a
set of inputs and expected outputs.
Figure 1.1 portrays a life cycle model for testing. Notice that, in the development phases,
three opportunities arise for errors to be made, resulting in faults that may propagate through the
remainder of the development process. The fault resolution step is another opportunity for errors
(and new faults). When a fix causes formerly correct software to misbehave, the fix is deficient. We
will revisit this when we discuss regression testing.
From this sequence of terms, we see that test cases occupy a central position in testing. The
process of testing can be subdivided into separate steps: test planning, test case development, running test cases, and evaluating test results. The focus of this book is how to identify useful sets of
test cases.
1.2  Test Cases
The essence of software testing is to determine a set of test cases for the item to be tested. A test
case is (or should be) a recognized work product. A complete test case will contain a test case identifier, a brief statement of purpose (e.g., a business rule), a description of preconditions, the actual
test case inputs, the expected outputs, a description of expected postconditions, and an execution
history. The execution history is primarily for test management use—it may contain the date when
the test was run, the person who ran it, the version on which it was run, and the pass/fail result.
Spec
Fault
Fault
Fault Incident
Design
Coding Classify
fault
Isolate
fault
Fault
resolution

A testing life cycle.

relates failures only to faults of commission. How can we deal with failures that correspond to
faults of omission? We can push this still further: what about faults that never happen to execute,
or perhaps do not execute for a long time? Reviews (see Chapter 22) prevent many failures by finding faults; in fact, well-done reviews can find faults of omission.
Incident—When a failure occurs, it may or may not be readily apparent to the user (or customer or tester). An incident is the symptom associated with a failure that alerts the user to the
occurrence of a failure.
Test—Testing is obviously concerned with errors, faults, failures, and incidents. A test is the
act of exercising software with test cases. A test has two distinct goals: to find failures or to demonstrate correct execution.
Test case—A test case has an identity and is associated with a program behavior. It also has a
set of inputs and expected outputs.
Figure 1.1 portrays a life cycle model for testing. Notice that, in the development phases,
three opportunities arise for errors to be made, resulting in faults that may propagate through the
remainder of the development process. The fault resolution step is another opportunity for errors
(and new faults). When a fix causes formerly correct software to misbehave, the fix is deficient. We
will revisit this when we discuss regression testing.
From this sequence of terms, we see that test cases occupy a central position in testing. The
process of testing can be subdivided into separate steps: test planning, test case development, running test cases, and evaluating test results. The focus of this book is how to identify useful sets of
test cases.

